#!/usr/bin/env python3

"""
This script is used to run flocking simulations. Refer to the README or list
existing options using:
    vmodel --help
"""

import argparse
import functools
import itertools
import os
import sys
import time
import warnings
import random
import math

import matplotlib.pyplot as plt
import numpy as np
import psutil
import tqdm
import yaml
from vmodel import geometry
from vmodel import liveplot as plot
from vmodel import metrics
from vmodel.core import update_single
from vmodel.dataset import create_dataset, generate_filename, save_dataset
from vmodel.flocking import olfati_saber_simplified, reynolds
from vmodel.random import random_positions
from vmodel.util.args import parse_vmodel_args
from vmodel.util.multiprocessing import get_silent_pool
from vmodel.util.util import human_readable as hr
from vmodel.visibility import visibility_graph
from vmodel.math import limit_norm

import scipy.spatial

SCRIPT = os.path.basename(__file__)

def circle_sections(divisions, radius=1):
    # the difference between angles in radians -- don't bother with degrees
    angle = 2 * math.pi / divisions

    # a list of all angles using a list comprehension
    angles = [i*angle for i in range(len(divisions))]

    # finally return the coordinates on the circle as a list of 2-tuples
    return [(radius*math.cos(a), radius*math.sin(a)) for a in angles]

def getCOM(positions):
    return np.mean(positions, axis = 0)

def init_pos(N, cC, sigma_space = 0.5):
    circle = cC
    
    rep_range = 1
    M_PI = math.pi
    Ncir = int(2*M_PI*circle) # # of particles fitting on current circle (1st. circle less)
    Ncap = Ncir    # # of particle which totally fit on all cicles including current one
    ccircle = 0    # # of particles on current circle

    angle = []

    out_pos = []


    rand_idx = list(range(N))
    rand1 = np.random.uniform(1,0,N)
    rand2 = np.random.uniform(1,0,N)
    random.shuffle(rand_idx)
    allprey = list(np.zeros((N,2)))

    for i in range(N):


        ii = rand_idx[i]
        if i == Ncap:
            circle += 1
            Ncir = int(2*M_PI*circle); # length of circumference
            Ncap += Ncir
            ccircle = 0

        angle = 2*M_PI*ccircle/Ncir

        x0 = rep_range*circle*np.cos(angle) + sigma_space*rand1[i]
        x1 = rep_range*circle*np.sin(angle) + sigma_space*rand2[i]

        allprey[ii] = [x0, x1]
        ccircle += 1
                
    return np.array(allprey)
            


def run(r, args, func):

    # Set numpy random seed
    np.random.seed(args.seed[r])
    pred_hunt = False




    # Shorthands for arguments
    nagents, dt = args.num_agents, args.delta_time
    
    if args.progress:
        pbar = tqdm.tqdm(total=args.num_timesteps, unit=' timesteps',
                         desc=f'[vmodel] [run {r + 1}]', position=r)

    data = argparse.Namespace()
    data.time, data.pos, data.vel, data.vis, data.dist, data.flee = [], [], [], [], [], []

    if args.plot:
        # _, (axpos, axdist, axvel) = plt.subplots(num='Plot', figsize=(7, 10), nrows=3,
        #                                          gridspec_kw={'height_ratios': [2, 1, 1]})
        _, axpos = plt.subplots(num='Plot', figsize=(7, 7))
        _, (axdist, axvel, axmet) = plt.subplots(num='State', nrows=3, figsize=(7, 7))

    # Compute metrics only when plotting them
    if args.plot_metrics:
        # _, axmet = plt.subplots(num='Metrics', figsize=(7, 7))
        data.ord, data.con, data.union, data.aspect = [], [], [], []


    

    pred_start = False
    positions = init_pos(args.num_agents, 1)
    
    prey_flee = np.zeros((args.num_agents, 2))
    
    
    positions_p = init_pos(args.num_preds, 10)
    
    
    #set first agent as predator position
    #positions[0] = [-20,-20]
    pastCOM_set = False

    #INITIATE preds and preys
    velocities = np.zeros_like(positions)
    
    #INITIATE AS MILLING
    com = ((np.mean(positions[:,0]), np.mean(positions[:,1])))
    dir_com = com - positions
    
    for i in range(len(positions[:,0])):
        
        A = dir_com[i,:]

        theta = np.radians(90)
        c, s = np.cos(theta), np.sin(theta)
        R = np.array(((c,-s), (s, c)))
        

        A = np.dot(R, A)
        A /= np.linalg.norm(A)
        if args.millstart == 1:
            velocities[i,:] = A
    
    
    
    velocities_p = np.zeros_like(positions_p)
    velocities = np.append(velocities,velocities_p, axis = 0)
    
    
    
    
    
    positions = np.append(positions,positions_p, axis = 0)
    
    #for testing single agent
    #positions[0] = 0,0
    #velocities[0] = -1,0

    
  

    if args.parallel_agents:
        pool = get_silent_pool(args.jobs)
        warnings.warn('Cannot generate reproducible results with multiprocessing')

    # Timestep zero: add initial conditions to data
    t = 0.0
    data.time.append(t)
    data.pos.append(positions.copy())
    data.vel.append(velocities.copy())
    data.dist.append(geometry.distance_matrix(positions))
    data.vis.append(visibility_graph(positions, args.radius))
    data.flee.append(prey_flee.copy())

    # Compute metrics for zeroth timestep
    if args.plot_metrics:
        compute_metrics(data)

    for k in itertools.count(start=1, step=1):
        #print("TIME", t)

        t += dt  # Integrate time

        #initiate predators at pred_time
        ### velocities may be redundant
        if t >= args.pred_time * dt and pred_start == False:
            com = getCOM(positions[0:args.num_agents])
            com_dist = []
            
            #get prey furthest from swarm
            for prey in range(args.num_agents):
            	com_dist.append(np.linalg.norm(positions[prey]-com))
            
            farthest_prey = np.max(com_dist)
            
            #print("com", com)
            
            
            if args.pred_angle < 0 or args.num_preds > 1:
                angle_pred = np.random.randint(0,360,args.num_preds)
            else:
                prey_heading = np.mean(velocities[:args.num_agents], axis = 0)
                prey_heading /= np.linalg.norm(prey_heading)
                prey_angle = 180*np.arctan2(prey_heading[1], prey_heading[0])/math.pi
                angle_pred = [prey_angle + args.pred_angle]
                #print(prey_heading, prey_angle, args.pred_angle, angle_pred)
                
                
            positions_p = []
            velocities_p = []
            #radius = args.pred_dist+farthest_prey
            radius = 21.5
            for ii in angle_pred:
                positions_p.append((radius*math.cos(ii*math.pi/180), radius*math.sin(ii*math.pi/180))+com)
            
            for jj in range(args.num_preds):
                
                velocities_p.append(com-positions_p[jj])
            

            positions[args.num_agents:args.num_agents+args.num_preds] = positions_p
            velocities[args.num_agents:args.num_agents+args.num_preds] = velocities_p
            #print("newpos", positions[args.num_agents:args.num_agents+args.num_preds])
            
            
            

        
        
        #hover preds on COM while not active
        pred_start_now = False #checks for moment of predation start  
        
        if t > args.pred_time * dt and t < args.pred_time * dt + dt:
            pred_start = True
            pred_start_now = True
        elif t > args.pred_time * dt:
            pred_start = True
            
        elif t <= args.pred_time * dt: 
            pred_start = False
            com = getCOM(positions[0:args.num_agents-1])
            for jj in range(args.num_preds):
                positions[jj+args.num_agents] = com
            
        
        if args.num_timesteps is not None and k >= args.num_timesteps:
            break

        if args.progress:
            pbar.update(1)

        # List to hold precomputed distance and visibilityconcatenate data
        vis_list, dist_list = [], []
        
        # Compute all distances between agents
        dist_full = scipy.spatial.distance.cdist(positions, positions)

        # Compute updates, either in parallel or sequentially
        if args.parallel_agents:
            args_list = [(i, positions, velocities, prey_flee, func, args, pred_hunt, t, pastCOM_set, pred_start, dist_full) for i in range(nagents+args.num_preds)]
            updates = pool.starmap_async(update_single, args_list).get(9999999)
        else:
            updates = [update_single(i, positions, velocities, prey_flee, func, args, pred_hunt, t, pastCOM_set, pred_start, dist_full) for i in range(nagents+args.num_preds)]
            

        
        for i in range(nagents+args.num_preds):

            cmd, cache, pred_hunt, pastCOM, pos_prey, prey_flee = updates[i]
            

            if pred_start == False and i >= args.num_agents:
                cmd = np.array((0,0))
            #elif i >= args.num_agents:
            elif i >= args.num_agents and pred_start_now:
                com = getCOM(positions[0:args.num_agents-1])
                velocities[i] = com-positions[i]
                #com_vis = getCOM(pos_prey)
            #    print("pos_prey",pos_prey)
            
                cmd = limit_norm(com-positions[i], 1)*2
                
            #    print(com_vis, cmd, positions[i], pos_prey)
            
            if pastCOM == True:
                pastCOM_set = True

            # Compute new position from velocity command
            #print(i, cmd)
            pos = positions[i] + cmd * dt


            # Save position and velocity
            

            positions[i] = pos
            velocities[i] = cmd

            # Save precomputed items
            vis_list.append(cache.vis.copy())
            dist_list.append(cache.dist.copy())
            
            
            
        

        
        
        
        # Save data
        if t >= 0:
        #if pred_start == True:
            if k % args.save_every == 0:
                data.time.append(t)
                data.pos.append(positions.copy())
                data.vel.append(velocities.copy())
                data.flee.append(prey_flee.copy())
                prey_flee = np.zeros((args.num_agents, 2))
                
                # Save visbility in any case
                vmat = [np.insert(vs, i, False) for i, vs in enumerate(vis_list)]
                data.vis.append(np.array(vmat))

                if not args.no_save_precomputed or args.plot:




                    # Save distance *only* when plotting (can easily be re-computed)
                    # Note: memory requirements blow up if this if-statement is not there
                    if args.plot:
                        dmat = [np.insert(ds, i, 0.0) for i, ds in enumerate(dist_list)]
                        data.dist.append(np.array(dmat))

                if args.plot_metrics:
                    compute_metrics(data)

        # Plotting
        if args.plot or args.plot_metrics:
            last_step = (args.num_timesteps is not None and k + 1 == args.num_timesteps)
            if k % args.plot_every == 0 or last_step:
                if args.plot:
                    plot.plot_all(axpos, data, args)
                    # plot_agents(axpos, data, args)
                    plot_distances(axdist, data, args)
                    plot_speed(axvel, data, args)
                    # plot.plot_clutter(axpos, clutter_list)
                if args.plot_metrics:
                    plot_metrics(axmet, data)

                # Wait for keypress if blocking, otherwise wait for dt and continue
                if args.plot_blocking:
                    while plt.waitforbuttonpress() is False:  # false -> mouse press
                        pass  # do nothing until true -> key press
                else:
                    plt.pause(args.delta_time)

    if args.plot:
        plt.show()
    #print(np.shape(data.vis))
    del data.dist  # Save memory. Distance matrix can easily be re-computed...

    # Delete precomputed data if we're not saving it anyways...
    #if args.no_save_precomputed:
    #    del data.vis
    
    
    
    return data


def compute_metrics(data):
    # data.con.append(metrics.connectivity(data.vis[-1]))
    data.con.append(metrics.connectivity(data.vis[-1]))
    data.union.append(metrics.union(data.vis[-1]))
    data.ord.append(metrics.order(data.vel[-1]))
    data.aspect.append(metrics.aspect_ratio(data.pos[-1]))


def plot_distances(ax, data, args):
    ax.clear()
    plot.plot_distances(ax, data.dist, data.time, radius=args.radius)
    ax.set(xlabel='time [s]', ylabel='distance [m]')
    ax.set(xlim=(0, data.time[-1]), ylim=(0, None))
    ax.legend(loc='lower right')
    ax.grid(True)


def plot_speed(ax, data, args):
    ax.clear()
    plot.plot_speed(ax, data.vel, data.time)
    ax.set(xlabel='time [s]', ylabel='speed [m/s]')
    ax.set(xlim=(0, data.time[-1]), ylim=(0, None))
    ax.legend(loc='upper right')
    ax.grid(True)


def plot_metrics(ax, data):
    ax.clear()

    # Plot order
    plot.plot_metric(ax, data.ord, data.time, name='order',
                     color='tab:green')

    # Plot connectivity
    plot.plot_metric(ax, data.con, data.time, name='connectivity',
                     color='tab:blue')

    # Plot union
    plot.plot_metric(ax, data.union, data.time, name='union',
                     color='tab:orange')

    # Plot aspect
    plot.plot_metric(ax, data.aspect, data.time, name='aspect ratio',
                     color='tab:cyan')

    ax.set(xlabel='time [s]', ylabel='metric [?]')
    ax.set(xlim=(0, data.time[-1]), ylim=(0, None))
    ax.legend(loc='lower right')
    ax.grid(True)


def main():

    args = parse_vmodel_args()

    # Load arguments from file (overwrites CLI arguments!)
    if args.file != '':
        file_dict = yaml.load(open(args.file, 'r'), Loader=yaml.FullLoader)
        args.__dict__.update(file_dict)

    # Define convenience print function (only prints in verbose mode)
    def vprint(*pargs, **kwargs):
        if args.verbose:
            print(f'[{SCRIPT}]', *pargs, **kwargs)
    eprint = lambda *args, **kwargs: vprint(*args, **kwargs, file=sys.stderr)

    # Only perception radius or perception angle can be defined
    if args.perception_radius > 0 and args.perception_angle > 0:
        eprint('Define either perception radius or angle, not both')
        sys.exit(-1)

    if args.migration_point and args.migration_dir:
        eprint('Define either migration point or migration direction, not both')
        sys.exit(-1)

    # Save current git hash (for repeatable experiments)
    try:
        import git
        repo = git.Repo(os.path.realpath(__file__), search_parent_directories=True)
        args.git_hash = repo.head.object.hexsha
        args.git_branch = repo.active_branch.name
    except ImportError:
        eprint('Install gitpython to save current git branch and hash')
        exit()

    # Sample and save random seed for repeatable experiments
    if args.seed is None:
        # Sample positive 31 bit integers
        args.seed = np.random.randint(2 ** 31 - 1, size=args.num_runs)
    elif isinstance(args.seed, (int, float)):
        # Use the same seed for each run
        args.seed = np.full(args.num_runs, args.seed)
    elif isinstance(args.seed, list):
        # If we pass multiple seed values, we are trying to run the same experiment again
        if len(args.seed) != args.num_runs:
            eprint('If providing list of seeds, provide one for each run')
            exit(0)
        args.seed = np.array(args.seed)

    vprint(f'Using random seed: {args.seed.tolist()}')

    # Check if we have enough memory available
    mem = psutil.virtual_memory()
    num_bytes_float64, num_states = 8, 2  # position and velocity
    num_per_step = args.num_runs * args.num_agents * args.num_dims / args.save_every
    num_bytes_per_step = num_per_step * num_bytes_float64 * num_states
    if args.num_timesteps is not None:
        mem_req = num_bytes_per_step * args.num_timesteps
        vprint(f'RAM required: {hr(mem_req)} (Used: {hr(mem.used)}/{hr(mem.total)})')
        if mem_req > mem.available:
            eprint('Script will consume more memory than is available. Exiting.')
            sys.exit(0)
    else:
        vprint(f'RAM required per timestep: {hr(num_bytes_per_step)}')

    # Derived variables
    args.radius_collision = 2 * args.radius
    args.radius_safety = 2 * args.radius_collision

    if args.algorithm == 'reynolds':
        # For Reynolds algorithm, infer separation gain in case of Reynolds flocking
        if args.ref_distance is not None:
            args.cohesion_gain = 1.0
            args.separation_gain = reynolds.infer_separation_gain3(args.ref_distance)
            vprint(f'Setting separation gain to {args.separation_gain:.2f}')
        func = functools.partial(reynolds.flock, cohesion_gain=args.cohesion_gain,
                                 separation_gain=args.separation_gain)
    elif args.algorithm == 'olfati':
        # For Olfati algorithm, set perception radius to 1.2 * dist
        if args.perception_radius is None:
            args.perception_radius = 1.2 * args.ref_distance
            vprint(f'Setting perception radius to {args.perception_radius:.2f}')
        func = functools.partial(olfati_saber_simplified.flock,
                                 distance=args.ref_distance,
                                 perception_radius=args.perception_radius)

    if args.spawn_distance is None:
        args.spawn_distance = args.ref_distance

    # Calculate desired radius of arena to keep agent number density constant
    args.mean_area_per_agent = np.pi * args.spawn_distance ** 2
    args.radius_arena = np.sqrt(args.num_agents * args.mean_area_per_agent / np.pi)

    # Agent density
    area_arena = np.pi * args.radius_arena ** 2
    agent_number_density = args.num_agents / area_arena
    vprint(f'Agent number density: {agent_number_density:.2f} agents/m^2')

    # Migration
    if len(args.migration_dir) > 0:
        direction = np.array(args.migration_dir)
        args.migration_dir = direction / np.linalg.norm(direction)

    args.radius_migration_point = 1.0  # only relevant for visual migration

    if args.plot and (args.save_every > args.plot_every):
        eprint('Cannot plot more often than saving. Consider lowering --save-every')
        exit()

    # No need for parallelizing runs if there is just one
    args.no_parallel_runs = True if args.num_runs == 1 else args.no_parallel_runs

    # Time run to obtain real-time factor
    time_start = time.time()

    if args.no_parallel_runs:
        datas = [run(r, args, func) for r in range(args.num_runs)]
    else:
        pool = get_silent_pool(args.jobs)
        args_list = [(r, args, func) for r in range(args.num_runs)]
        datas = pool.starmap_async(run, args_list).get(9999999)  # don't judge!

    duration = time.time() - time_start
    vprint(f'Total duration: {duration:.2f} seconds')

    if args.dry_run:
        vprint('Dry run. Exiting without writing data.')
        sys.exit(0)

    # Create dataset from multiple runs
    ds = create_dataset(datas, args)

    # Generate filename: date_args.ext
    fname = generate_filename(args)
    #fname = "/home/lars/vmodel/output/state.nc"
    # Save dataset and config file
    vprint(f'Saving {args.format} file: {fname}')
    save_dataset(ds, fname, args)


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        sys.exit(0)
